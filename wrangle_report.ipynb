{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangling: it is process of gathering, assessing, cleaning data. <br> In this report, we'll discuss the wrangling process of our project \n",
    "\n",
    "#### Step 1: Gather Data: <br> \n",
    "We've gathered data from twitter app with 3 different ways : \n",
    "\n",
    "**Way 1 \\ Csv file:** We imported needed libraries: **pandas** then downloaded the file and we read it by **.read_csv()**\n",
    "\n",
    "\n",
    "**Way 2 \\ Web Scraping:** We imported needed libraries: **requests** to send request to the server to got the file with **.tsv** extension then we converted it as **Csv file** and read it with **.read_csv()**\n",
    "\n",
    "**Way 3 \\ json Normalization:** We imported needed libraries: **json** to make normalization to the **.txt** file to be able to use it and to add some data then we converted the file into dataframe by using **.DataFrame()**\n",
    "\n",
    "\n",
    "#### Step 2: Assess Data: <br> \n",
    "We know have 3 data resources to assess them, we used **.head()** to get the first 5 rows for each resource which was **Visual Assessment**.\n",
    "Then we used **.info()** to get some information about: **columns names, data types, rows no, ...etc**, also we used **.isna().sum()** to chech NANs in each column and finally, we used **.duplicated().sum()** to get duplicated values in each column \n",
    "\n",
    "\n",
    "#### Step 3: Clean Data: <br>\n",
    "After documenting **quality and tidness issues** which were:\n",
    "##### Quality issues\n",
    "1.  In `twitter_archive` dataframe there are 5 columns with many NANs which are: <br> <br> `retweeted_status_id`,`retweeted_status_user_id`, `retweeted_status_timestamp`, `in_reply_to_status_id` and <br> <br> `in_reply_to_user_id` so we'll delete them <br> <br>\n",
    "\n",
    "2. In `twitter_archive` dataframe there is `expanded_urls` column with few NANs, so we'll fill it with mode <br><br> \n",
    "\n",
    "3. In `twitter_archive` dataframe, the columns `date` and `time` should be datetime datatype so we'll convert them by `.to_datetime()` and `to_timedelta` <br> <br>\n",
    "\n",
    "4. In `twitter_archive` dataframe, `source` column shouldn't include html tags so we'll remove them by function using `re` <br> <br>\n",
    "\n",
    "5. In `twitter_archive` dataframe, `tweet_id` column should be string datatype so we'll convert them by `.astype()` <br> <br> \n",
    "\n",
    "6. In `tweet_df` dataframe, `tweet_id` column should be string datatype so we'll convert them by `.astype()` <br> <br> \n",
    "\n",
    "7. In `img_df` dataframe, `p1_conf`, `p2_conf` and `p3_conf` columns should be float datatype so we'll convert them by `.astype()`  <br> <br>\n",
    "\n",
    "8. In `img_df` dataframe, `p1_dog`, `p2_dog` and `p3_dog` columns should be float datatype so we'll convert them by `.astype()`  <br> <br>\n",
    "\n",
    "##### Tidiness issues\n",
    "1. In `twitter_archive` dataframe, `timestamp` column contains date and time so we'll split it into 2 columns\n",
    "\n",
    "2. In `img_df` dataframe, all the columns are combined as one column so we'll split it into several columns\n",
    "\n",
    ", we started to clean data with these stratigies:\n",
    "\n",
    "**1) For NANs:** : \n",
    "\n",
    "* the column with many NANs will be deleted\n",
    "\n",
    "* the column with few NANs will be filled with mode value\n",
    "                   \n",
    "**2) For Data Types**: \n",
    "\n",
    "* datetime and deltatime >>> importing needed libraries then convert \n",
    "\n",
    "* str, float,int >>> using **astype()**\n",
    "                       \n",
    "                       \n",
    "**3) For Combined Columns**: * splitting by using **.split()** them then detecting any other issues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
